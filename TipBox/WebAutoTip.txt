***웹 크롤링(web crawling)***
    수많은 웹사이트들을 체계적으로 돌아다니면서 URL, 키워드 등을 수집하는 것. 보통 검색 엔진이 웹사이트를 인덱싱하기 위해서 사용됨.



***웹 스크래핑(web scraping)***
    웹사이트에서 필요한 데이터를 긁어오는 것.
    
    
    
***웹 가져오기***
    request
        웹사이트의 패킷 내용을 가져올 수 있는 라이브러리

            import requests

            response=requests.get("https://fancyurl.com")
            print(response.text)

            rating_pages=[]
            #https://workey.codeit.kr/ratings/index?year=2010&month=1&weekIndex=0
            for i in range(5):
                url="https://workey.codeit.kr/ratings/index?year=2010&month=1&weekIndex={}".format(i)
                rating_page=requests.get(url).text
                rating_pages.append(rating_page)

            print(rating_pages)
    

***웹 스타일링***
    css 선택자
    
        css로 스타일링 하는 방법
            
            태그에 style 속성으로 넣어도되지만
            
                <p style={color:white;}>
                
            css파일을 따로 만들고 html 파일 head태그 안에
            
                <link rel="stylesheet" href="css파일 위치">
                
            을 만들고 새로만든 css 파일에는
            
                p{
                    color: white;
                }
                
            이런 식으로 스타일링하면 된다.
            
            
        선택자
            스타일을 넣어줄 때, p,a와 같은 태그에 스타일링을 하면 모든 p태그,
            a태그에 스타일이 들어간다.
            스타일링을 할 때 특정 태그를 선택하고 싶은 경우가 많은데
            이때 특정 태그 하나만 선택하려면 id,
            여러 태그를 선택하려면 class를 사용하면 된다
            이러한 id,class와 같은 것을 선택자라고 한다
            
            id 속성을 넣으려면 먼저 특정 태그에 id 속성을 넣고
            
                <li id='food'>
                
            css 파일에서는
                
                #li{
                    color:white;
                }
                
            태그 앞에 #을 넣고 스타일링을 넣으면 된다
            마찬가지로 class 속성을 넣으려면 먼저 특정 태그에 class 속성을 넣고
            
                <li class='food'>
                
            css 파일에서는
                
                .li{
                    color:white;
                }
                
            태그 앞에 .을 넣고 스타일링을 넣으면 된다
            
            
            한편 이러한 선택자는 꼭 id,class만 있는 건 아닌데,
            예를들어 a태그는 href 속성을 통해 다른 웹페이지로 이동 할 수 있게
            만드는 하이퍼링크 기능이 있다.
            
                <a href="https://fancyurl.com">
                
            그런데 css 파일에서
            
                [href="https://fancyurl.com"]{
                    color:white;
                }
                
            이런 식으로 특정 속성을 스타일하면 href 속성으로 저 주소를 가지고 
            있는 모든 태그의 글자색이 변경된다.
            
            위의 예시를 일반화하면 다음과 같다.
                
                [attr="value"]
                
            
            그 외 선택자
                or

                    h2,p{
                        color:white;
                    }

                and

                    b.inner1{
                        color:white;
                    }

                중첩

                    li i{
                        color:white;
                    }

                직속자식

                    li > i{
                        color:white;
                    }

                와일드카드

                    li *{
                        color:white;
                    }
                    
                중첩랑 직속자식이랑 혼동될 수 있는데
                중첩은 자식이기만하면 되고 직속은 한단계 아래 자식이어야만
                적용이된다.
                
                
                
***웹에서 데이터 얻기***
    table
        웹스크래핑을 할 때 자주 다루게되는 요소, 표형태를 말함
        
            <table>
                <tbody>
                    <tr>
                        <th></th>
                        <th></th>
                        <th></th>
                    </tr>
                    <tr>
                    </tr>
                    <tr>
                    </tr>
                    <tr>
                    </tr>
                </tbody>
            </table>
        
        tr는 table row, th는 table head를 말함
        th는 보통 테이블의 columns의 정보를 나타내는 경우가 많음
    
    
    Beautiful Soup
        request로 얻은 데이터에서 필요한 정보만 산출하는 라이브러리
        
        원하는 태그 선택하기
        
            soup.select는 해당 되는 태그가 하나라도 리스트를 반환한다.
            만약 리스트가 아니라 그 값만 얻고 싶다면 soup.select_one메소드를 사용하면 된다.
       
                from bs4 import BeautifulSoup as bs
                import requests            

                #티비랭킹닷컴: https://workey.codeit.kr/ratings
                page=requests.get("https://workey.codeit.kr/ratings").text
                soup=bs(page,'html.parser')    #파서로 데이터를 분석,정리하고 그 결과를 soup에 담음
                print(soup.prettyify())    #tap문자 같은걸 추가해서 전체 코드를 이쁘게 보여줌
                print(soup.select('tagname'))    #해당 태그를 출력함
                print(soup.select('table'))

                program_title_tags=soup.select('td.program')

                program_titles=[]

                for tag in program_title_tags:
                    program_titles.append(tag.get_text())    #태그의 텍스트를 추출함

                print(program_titles)


            슬라이싱, 인덱싱도 가능하다 또한 soup가 아닌 일반 태그에서도 가능하다.
            
                td_tags=soup.select('td')[:4]
                tr_tag=soup.select('tr')[1]
                td_tags=tr_tag.select('td')
                
                
            find 와 find_all
                find()는 select_one()과 비슷하고, find_all()은 select()와 비슷
                
                soup.find_all('tagname')
                soup.find_all(['tagname1', 'tagname2'])
                tag.find_all(True)    #모든 태그 찾기
                soup.find_all('p', id="some-id", class_="some-class")
                #class는 예약어여서 _class로 사용해야됨
                soup.find_all('p', id=True, class_=False)
                
                
            태그에서 텍스트 빼오기
                기본적으로 사용하는 get_text() 말고
                strings, stripped_strings가 있음
                
                    print(list(tag.strings))
                    print(list(tag.stripped_strings))
                    
            태그에서 속성 빼오기
                태그의 속성 안에는 웹사이트 주소나 이미지 주소같은 유의미한 데이터가 많음
                태그의 모든 속성은 사전 형태로 저장되어있음
                    
                    soup.select_one('img')['src']
                    
                        >>/images/img.png
                    
                    soup.select_one('img').attrs
                    
                        >>{'src':'/images/img.png','id':'qwertyou'}
                
                
            Beautiful Soup 간결하게 쓰기
                
                .tagname 문법
                
                    soup.tagname # soup.select_one('tagname')과 동일
                    tag.tagname # tag.select_one('tagname')과 동일
                
                메소드 체이닝
                    메소드 체이닝은 메소드의 리턴값을 변수에 저장하지 않고, 
                    리턴값에 바로 또 다른 메소드를 호출하는 것을 뜻함
                
                        div_tag = soup.select_one('div.data')
                        keyword = div_tag.div.p.b.get_text()    #메소드 체이닝
                        print(keyword)
                        
            
            데이터를 액셀 파일로
                
                import requests
                from bs4 import BeautifulSoup as bs
                from openpyxl import Workbook
                
                wb=Workbook(write_only=True)    #워크북 생성
                ws=wb.create_sheet('TV Ratings')    #워크시트 생성
                ws.append(['순위','채널','프로그램','시청률'])    #인덱스row추가
                
                page=requests.get("https://workey.codeit.kr/ratings/index").text
                
                soup=bs(page,'html.parser')
                for tr_tag in soup.select('tr')[1:]:    #보통 table의 첫 tr태그는 th일 확률이 있음 이런 경우 슬라이싱해야댐
                    td_tags=tr_tag.select('td')
                    row=[
                        td_tags[0].get_text(),
                        td_tags[1].get_text(),
                        td_tags[2].get_text(),
                        td_tags[3].get_text()
                    ]
                
                wb.save('시청률.xlsx')    #워크북 저장, 확장자 xlsx 잊지말기
                
            
            데이터를 csv 파일로
                
                import csv
                csv_file = open('file_name.csv', 'w')
                csv_writer = csv.writer(csv_file)
                csv_writer.writerow([data1, data2, ...])    # CSV 파일에 행 추가
                csv_file.close()    # CSV 파일 닫기
                


***웹사이트 제어하기***
    
    Selenium 라이브러리