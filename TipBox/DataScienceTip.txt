Jupyter Notebook에서 공부한 내용임

***edit mode와 command mode***
    ctrl+enter 그냥 실행
    alt+enter 실행 후 아래에 셀 생성(있으면 이동)
    dd 셀삭제
    a 선택 셀 위에 셀 생성
    b 선택 셀 아래에 셀 생성
    하나 지정 후 특정 셀 shift 누르면 거기까지 선택 가능
    
    
***출력***
    print를 사용해서 출력해도 되지만
    그냥 출력하고 싶은 변수나 값 등을 적기만 해도 출력이 됨
    단 이러면 마지막 하나만 출력이됨 그리고 이런 식으로 출력을 하면
    주피터에서 이쁘게 출력해주는 등 일반적인 print()로 출력하는 것과
    다른 결과가 나올 수 있음
    
    
***numpy***
    numerical python의 준말
    숫자와 관련된 파이썬 도구
    numpy 배열은 일반적인 list와 유사하지만 ds를 다루는데 적합한 자료형임
    list와의 차이점은 속도가 훨씬 빠르고, 간단한하지만 같은 자료형만 넣어야하는 단점이 있다.
    
        import numpy
        array1=numpy.array([2,3,5,7,11,13,17,19,23,31])
        array1
            >>array([ 2,  3,  5,  7, 11, 13, 17, 19, 23, 31])
            
        array2=numpy.array([[1,2,3,4,],[5,6,7,8,],[9,10,11,12]])
        type(array2)
            >>numpy.ndarray
        array2
            >>array([[ 1,  2,  3,  4],
               [ 5,  6,  7,  8],
               [ 9, 10, 11, 12]])
        array2.shape
            >>(3, 4)
        array2.size
            >>12
            
            
    numpy array를 만드는 다양한 방법
        numpy 모듈의 array 메소드에 파라미터로 리스트를 넘겨주면 됨
        
            array1 = numpy.array([2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31])
        
        numpy 모듈의 fill 메소드를 사용하면 모든 값이 같은 numpy array 생성
            
            array2 = numpy.full(6,7)        #[7 7 7 7 7 7]
            array3 = numpy.zeros(6, dtype=int)        #[0 0 0 0 0 0]
            array4 = numpy.ones(6, dtype=int)        #[1 1 1 1 1 1]
            
        램덤한 값들을 생성하고 싶다면 numpy 모듈안에 random 모듈의 random 함수를
        사용하면 됨
        
            array5 = numpy.random.random(6)
            #[0.42214929 0.45275673 0.57978413 0.61417065 0.39448558 0.03347601]
            
            array6 = numpy.random.random(6)
            #[0.42521953 0.65091589 0.94045742 0.18138103 0.27150749 0.8450694 ]
        
        연속된 값들을 생성하고 싶다면 numpy 모듈의 arange 함수를 이용해 생성
        arange() 함수는 range()와 매우 유사하게 동작함
        
        파라미터가 1개라면 0~m-1까지의 값들이 담긴 numpy array가 리턴됨
        파라미터가 2개라면 n~m-1까지의 값들이 담긴 numpy array가 리턴됨
        파라미터가 3개라면 n~m-1까지의 값들 중 간격이 s인 numpy array가 리턴됨
        
            array7 = numpy.arange(6)    #[0 1 2 3 4 5]
            array8 = numpy.arange(2, 7)    #[2 3 4 5 6]
            array9 = numpy.arange(3, 17, 3)    #[ 3  6  9 12 15]
            
            
    numpy 인덱싱/슬라이싱

        import numpy as np

        arr=np.array([2,3,5,7,5,9,0,4,2,1,2])

        arr[2]        5
        arr[1]        3

        arr[-1]        2
        arr[-2]        1

        arr[[1,3,6]]        3,7,0

        idx=np.array([3,1,2])        

        arr[idx]        7,3,5        #numpy array안에 numpy array 넣을 수 있음

        arr[2:5]        5,7,5
        arr[:5]        2,3,5,7,5
        arr[1:4:2]        3,7
            
            
    numpy 기본연산
        
        import numpy as np
        
        array1=np.arange(10)    #[0,1,2,3,4,5,6,7,8,9]
        array2=np.arange(10,20)
        
        array1*2        #[0,2,4,6,8,10,12,14,16,18]
        
        array1*array2    #[10, 12, 14, 16, 18, 20, 22, 24, 26, 28]
        
        
    numpy 불린연산
        numpy array에는 불린 값도 넣어 둘 수 있고 연산도 할 수 있다.
        
            import numpy as np

            array1=np.array([2,3,5,7,11,13,17,19,23,29,31])
            array1>4      

                >>array([False,False,True,True,True,True,True,True,True,True,True])

            booleans=array1<4         #불린값들이 담긴 numpy array 생성
            filter=np.where(booleans)        #참 값의 인덱스를 담아둔 numpy array 생성
            filter   
            
                >>(array([ 2,  3,  4,  5,  6,  7,  8,  9, 10]),)
            
            array1[filter]        #인덱스가 적힌 값 출력
            
                >>array([ 5,  7, 11, 13, 17, 19, 23, 29, 31])
                
                
    numpy 라이브러리의 기본적인 통계 기능
        array1.max()    최대값
        array1.min()    최소값
        array1.mean()    평균
        np.median(array2)    중앙값
        array1.std()    표준편차
        array1.var()    분산
    
    
***pandas***
    numpy를 이용해 만듬
    
    Series
        Series는 1차원 array를 다루는 pandas 라이브러리의 고유 자료형
        numpy array랑 pandas Series랑 비슷한 기능을 한다고 생각하면 됨
            
            pd.Series(['dongwook', 50, 86]
            
        Series는 list로 변환 가능
        
    
    numpy array도 표형식의 2차원 배열 사용가능한데 굳이 pandas를 쓰는 이유
        numpy array에서는 row나 column이 숫자여만 했는데
        pandas DataFrame에서는 문자열이나 다른 자료형이어도 상관없음
        표 안에 데이터도 숫자만 넣을 수 있던 numpy array와는 달리
        pandas DataFrame에서는 다른 자료형이어도 상관없음
        그 외에도 외부데이터 읽고 쓰기, 데이터분석, 데이터 정리 등등
        
        
    DataFrame
        표형식의 데이터를 담는 자료형
        가로로 나열되어 있는 줄을 행    row/index    레코드
        세로로 나열되어 있는 줄을 열    column        데이터의 특징
        
        
    DataFrame 기본사용
        보통 aliasing으로 pd라고 한다.
            import pandas as pd
            two_dimensional_list=[['asdf',23,42],['fads',14,89],['poui',53,26]]
            my_df=pd.DataFrame(two_dimensional_list, columns=['name','score1','score2'],index=['a','b','c',])
            my_df    
            #기본적으로 columns나 index를 설정하지 않으면 0,1,2,3 이런식으로 
            #기본적으로 설정되기 때문에 이름을 짓고 싶다면 데이터프레임 설정할 때 지어줘야함        

                >>
                    name	score1	score2
                a	asdf	23	    42
                b	fads	14	    89
                c	poui	53	    26

            type(my_df)

                >>pandas.core.frame.DataFrame

            my_df.columns    #데이터프레임의 column 출력

                >>Index(['name', 'score1', 'score2'], dtype='object')

            my_df.index    #데이터프레임의 row 출력

                >>Index(['a', 'b', 'c'], dtype='object')

            my_df.dtypes    #데이터프레임의 각각의 컬럼들의 자료형 출력

                >>
                name      object    #object는 pandas에서 문자열 같은 개념
                score1     int64
                score2     int64
                dtype: object
                
                #int64	정수
                #float64	소수
                #object	텍스트
                #bool	불린(참과 거짓)
                #datetime64	날짜와 시간
                #category	카테고리

                #각각의 컬럼은 서로 다른 자료형을 가져도 되지만
                #하나의 컬럼은 무조건 같은 자료형이 담겨야하는 것을 알 수 있음

        From list of lists, array of arrays, list of series
        2차원 리스트나 2차원 numpy array로 DataFrame을 만들 수 있음 
        심지어 pandas Series를 담고 있는 리스트로도 DataFrame 생성 가능

            import numpy as np
            import pandas as pd

            two_dimensional_list = [['dongwook', 50, 86], ['sineui', 89, 31], ['ikjoong', 68, 91], ['yoonsoo', 88, 75]]
            two_dimensional_array = np.array(two_dimensional_list)
            list_of_series = [
                pd.Series(['dongwook', 50, 86]), 
                pd.Series(['sineui', 89, 31]), 
                pd.Series(['ikjoong', 68, 91]), 
                pd.Series(['yoonsoo', 88, 75])
            ]

            # 아래 셋은 모두 동일함
            df1 = pd.DataFrame(two_dimensional_list)
            df2 = pd.DataFrame(two_dimensional_array)
            df3 = pd.DataFrame(list_of_series)

            print(df1)

                >>
                          0   1   2
                0  dongwook  50  86
                1    sineui  89  31
                2   ikjoong  68  91
                3   yoonsoo  88  75

        
        From dict of lists, dict of arrays, dict of series
        파이썬 사전(dictionary)으로도 DataFrame을 만들 수 있음
        사전의 key로는 column 이름을 쓰고, 그 column에 해당하는 리스트, 
        numpy array, 혹은 pandas Series를 사전의 value로 넣어주면 됨
    
            import numpy as np
            import pandas as pd

            names = ['dongwook', 'sineui', 'ikjoong', 'yoonsoo']
            english_scores = [50, 89, 68, 88]
            math_scores = [86, 31, 91, 75]

            dict1 = {
                'name': names, 
                'english_score': english_scores, 
                'math_score': math_scores
            }

            dict2 = {
                'name': np.array(names), 
                'english_score': np.array(english_scores), 
                'math_score': np.array(math_scores)
            }

            dict3 = {
                'name': pd.Series(names), 
                'english_score': pd.Series(english_scores), 
                'math_score': pd.Series(math_scores)
            }


            # 아래 셋은 모두 동일함
            df1 = pd.DataFrame(dict1)
            df2 = pd.DataFrame(dict2)
            df3 = pd.DataFrame(dict3)

            print(df1)
            
                >>
                       name  english_score  math_score
                0  dongwook             50          86
                1    sineui             89          31
                2   ikjoong             68          91
                3   yoonsoo             88          75
                
        From list of dicts
        리스트가 담긴 사전이 아니라, 
        사전이 담긴 리스트로도 DataFrame을 만들 수 있음

            import numpy as np
            import pandas as pd

            my_list = [
                {'name': 'dongwook', 'english_score': 50, 'math_score': 86},
                {'name': 'sineui', 'english_score': 89, 'math_score': 31},
                {'name': 'ikjoong', 'english_score': 68, 'math_score': 91},
                {'name': 'yoonsoo', 'english_score': 88, 'math_score': 75}
            ]

            df = pd.DataFrame(my_list)
            print(df)
            
            >>
                   english_score  math_score      name
                0             50          86  dongwook
                1             89          31    sineui
                2             68          91   ikjoong
                3             88          75   yoonsoo
                
    csv(comma seperated values)
        보통 첫 줄에 컬림이름들이 나와있는 줄이 있는데 헤더라고 함
        
            import pandas as pd
            iphone_df=pd.read_csv('data/iphone.csv')
            iphone_df

                >>
                    Unnamed: 0	출시일	디스플레이	메모리	출시 버전	Face ID
                0	iPhone 7	2016-09-16	4.7	2GB	iOS 10.0	No
                1	iPhone 7 Plus	2016-09-16	5.5	3GB	iOS 10.0	No
                2	iPhone 8	2017-09-22	4.7	2GB	iOS 11.0	No
                3	iPhone 8 Plus	2017-09-22	5.5	3GB	iOS 11.0	No
                4	iPhone X	2017-11-03	5.8	3GB	iOS 11.1	Yes
                5	iPhone XS	2018-09-21	5.8	4GB	iOS 12.0	Yes
                6	iPhone XS Max	2018-09-21	6.5	4GB	iOS 12.0	Yes
        
        csv 파일의 처음을 자동으로 header로 인식해서 사용함 
        그러나 header 없이 바로 데이터가 나오는 경우도 있을 것이다.
        그러면 다음과같이 header가 없음을 설정하면 된다.
        
            iphone_df=pd.read_csv('data/iphone.csv',header=None)
            
        또 지금과 같이 가장 왼쪽 부분이 어색한데 가장 왼쪽 컬럼을 row 이름으로
        설정하면 된다.
            
            iphone_df=pd.read_csv('data/iphone.csv',index_col=0)
            
        
    DataFrame 인덱싱
        이전 버전에서는 

            iphone_df.loc[:,[True,False,True,True,False]]

        이런 식으로 문법을 사용하였는데 DataFrame의 row의 값이 10개라면
        다시말해 조건으로 건 인덱싱의 개수랑 row의 개수가 다르다면
        모자른 개수는 모두 false로 처리하고 초과한건 무시했는데
        현재는 정확히 개수가 맞아야한다고 함
        
            import pandas as pd
            iphone_df=pd.read_csv('data/iphone.csv',index_col=0)

            #특정 데이터 인덱싱
            iphone_df.loc['iPhone 8','메모리']

                >>'2GB'

            #특정 row나 column 인덱싱
            iphone_df.loc['iPhone 8']    #iphone_df.loc['iPhone 8',:] 랑 동일함

                >>
                출시일        2017-09-22
                디스플레이             4.7
                메모리               2GB
                출시 버전        iOS 11.0
                Face ID            No
                Name: iPhone 8, dtype: object


            iphone_df.loc[:,"디스플레이"]        #iphone_df["디스플레이"] 랑 동일함

                >>
                iPhone 7         4.7
                iPhone 7 Plus    5.5
                iPhone 8         4.7
                iPhone 8 Plus    5.5
                iPhone X         5.8
                iPhone XS        5.8
                iPhone XS Max    6.5
                Name: 디스플레이, dtype: float64

            type(iphone_df.loc[:,"디스플레이"])

                >>pandas.core.series.Series    #한줄은 Series 라고 생각하면 됨

            type(iphone_df.loc['iPhone 8','메모리'])   

                >>str

            #index 목록 및 데이터타입 확인
            iphone_df.index    
                >>
                Index(['iPhone 7', 'iPhone 7 Plus', 'iPhone 8', 'iPhone 8 Plus', 'iPhone X',
                   'iPhone XS', 'iPhone XS Max'],
                  dtype='object')

            #원하는 row를 리스트로 보내주면 여러개 선택가능
            iphone_df.loc[['iPhone 8','iPhone 8 Plus']]


            #슬라이싱도 가능
            iphone_df.loc[['iPhone 8','iPhone 8 Plus']]

                >>>
                출시일	디스플레이	메모리	출시 버전	Face ID
                iPhone 8	2017-09-22	4.7	2GB	iOS 11.0	No
                iPhone 8 Plus	2017-09-22	5.5	3GB	iOS 11.0	No

            iphone_df.loc[:'iPhone 8']

                >>>
                출시일	디스플레이	메모리	출시 버전	Face ID
                iPhone 7	2016-09-16	4.7	2GB	iOS 10.0	No
                iPhone 7 Plus	2016-09-16	5.5	3GB	iOS 10.0	No
                iPhone 8	2017-09-22	4.7	2GB	iOS 11.0	No

            #위에서 loc 안쓰고 인덱싱 하는거 슬라이싱에서는 안됨 
            iphone_df.loc[:,'메모리':'Face ID']

                >>>
                메모리	출시 버전	Face ID
                iPhone 7	2GB	iOS 10.0	No
                iPhone 7 Plus	3GB	iOS 10.0	No
                iPhone 8	2GB	iOS 11.0	No
                iPhone 8 Plus	3GB	iOS 11.0	No
                iPhone X	3GB	iOS 11.1	Yes
                iPhone XS	4GB	iOS 12.0	Yes
                iPhone XS Max	4GB	iOS 12.0	Yes

            iphone_df.loc['iPhone 7':'iPhone X','메모리':'Face ID']

                >>>
                메모리	출시 버전	Face ID
                iPhone 7	2GB	iOS 10.0	No
                iPhone 7 Plus	3GB	iOS 10.0	No
                iPhone 8	2GB	iOS 11.0	No
                iPhone 8 Plus	3GB	iOS 11.0	No
                iPhone X	3GB	iOS 11.1	Yes


            #불린타입 series도 인덱싱 가능
            iphone_df['디스플레이']>5

                iPhone 7         False
                iPhone 7 Plus     True
                iPhone 8         False
                iPhone 8 Plus     True
                iPhone X          True
                iPhone XS         True
                iPhone XS Max     True
                Name: 디스플레이, dtype: bool

            iphone_df.loc[iphone_df['디스플레이']>5]
            #iphone_df.loc[[False,True,False,True,True,True,True]]랑 같음

                출시일	디스플레이	메모리	출시 버전	Face ID
                iPhone 7 Plus	2016-09-16	5.5	3GB	iOS 10.0	No
                iPhone 8 Plus	2017-09-22	5.5	3GB	iOS 11.0	No
                iPhone X	2017-11-03	5.8	3GB	iOS 11.1	Yes
                iPhone XS	2018-09-21	5.8	4GB	iOS 12.0	Yes
                iPhone XS Max	2018-09-21	6.5	4GB	iOS 12.0	Yes

            #컬럼으로도 인덱싱 가능
            iphone_df.loc[:,[True,False,True,True,False]]

                출시일	메모리	출시 버전
                iPhone 7	2016-09-16	2GB	iOS 10.0
                iPhone 7 Plus	2016-09-16	3GB	iOS 10.0
                iPhone 8	2017-09-22	2GB	iOS 11.0
                iPhone 8 Plus	2017-09-22	3GB	iOS 11.0
                iPhone X	2017-11-03	3GB	iOS 11.1
                iPhone XS	2018-09-21	4GB	iOS 12.0
                iPhone XS Max	2018-09-21	4GB	iOS 12.0

            iphone_df['Face ID']=='Yes'

                iPhone 7         False
                iPhone 7 Plus    False
                iPhone 8         False
                iPhone 8 Plus    False
                iPhone X          True
                iPhone XS         True
                iPhone XS Max     True
                Name: Face ID, dtype: bool

            #조건연산자 사용가능 or은 | 사용하면 됨
            condition=(iphone_df['Face ID']=='Yes')&(iphone_df['디스플레이']>5)
            condition

                iPhone 7         False
                iPhone 7 Plus    False
                iPhone 8         False
                iPhone 8 Plus    False
                iPhone X          True
                iPhone XS         True
                iPhone XS Max     True
                dtype: bool
            
            #조건 응용하기
            iphone_df[condition]
            iphone_df[condition,'디스플레이']='양호'

            #iloc를 사용하면 숫자로 인덱싱할 수 있음
            iphone_df.iloc[2,4]
                >>
                'No'

            iphone_df.iloc[[1,3],[1,4]]
                >>
                디스플레이	Face ID
                iPhone 7 Plus	5.5	No
                iPhone 8 Plus	5.5	No

            iphone_df.iloc[3:,1:4]
                >>
                디스플레이	메모리	출시 버전
                iPhone 8 Plus	5.5	3GB	iOS 11.0
                iPhone X	5.8	3GB	iOS 11.1
                iPhone XS	5.8	4GB	iOS 12.0
                iPhone XS Max	6.5	4GB	iOS 12.0
                
        
    DataFrame에 값 쓰기
    
        iphone_df.loc['iPhone 8','출시 버전']
        
            >>
            'iOS 11.0'
            'iPhone 8'
            
        iphone_df.loc['iPhone 8','출시 버전']='iOS 11.5'
        iphone_df.loc['iPhone 8','출시 버전']
        
            >>
            'iOS 11.5'
            
        iphone_df.loc['iPhone 8']=['2016-09-25','4.7','4GB','iOS 13.0','No']
        iphone_df.loc['iPhone 8']
        
            >>
            출시일        2016-09-25
            디스플레이             4.7
            메모리               4GB
            출시 버전        iOS 13.0
            Face ID            No
            Name: iPhone 8, dtype: object
            
        iphone_df['face ID']='Yes'
        iphone_df
        
            >>
            출시일	디스플레이	메모리	출시 버전	Face ID	face ID
            iPhone 7	2016-09-16	4.7	2GB	iOS 10.0	No	Yes
            iPhone 7 Plus	2016-09-16	5.5	3GB	iOS 10.0	No	Yes
            iPhone 8	2016-09-25	4.7	4GB	iOS 13.0	No	Yes
            iPhone 8 Plus	2017-09-22	5.5	3GB	iOS 11.0	No	Yes
            iPhone X	2017-11-03	5.8	3GB	iOS 11.1	Yes	Yes
            iPhone XS	2018-09-21	5.8	4GB	iOS 12.0	Yes	Yes
            iPhone XS Max	2018-09-21	6.5	4GB	iOS 12.0	Yes	Yes
            
    
    DataFrame에 한 줄 단위,column,row 추가 삭제
        
        #row 추가
        iphone_df.loc['iPhone XR']=['2016-09-25','4.7','4GB','iOS 13.0','No','No']
        iphone_df
        
            >>
            출시일	디스플레이	메모리	출시 버전	Face ID	face ID
            iPhone 7	2016-09-16	4.7	2GB	iOS 10.0	No	Yes
            iPhone 7 Plus	2016-09-16	5.5	3GB	iOS 10.0	No	Yes
            iPhone 8	2016-09-25	4.7	4GB	iOS 13.0	No	Yes
            iPhone 8 Plus	2017-09-22	5.5	3GB	iOS 11.0	No	Yes
            iPhone X	2017-11-03	5.8	3GB	iOS 11.1	Yes	Yes
            iPhone XS	2018-09-21	5.8	4GB	iOS 12.0	Yes	Yes
            iPhone XS Max	2018-09-21	6.5	4GB	iOS 12.0	Yes	Yes
            iPhone XR	2016-09-25	4.7	4GB	iOS 13.0	No	No
         
        #column 삭제(원본 변형)
        iphone_df.drop('face ID',axis='columns',inplace=True)
        iphone_df
        
            >>
            출시일	디스플레이	메모리	출시 버전	Face ID
            iPhone 7	2016-09-16	4.7	2GB	iOS 10.0	No
            iPhone 7 Plus	2016-09-16	5.5	3GB	iOS 10.0	No
            iPhone 8	2016-09-25	4.7	4GB	iOS 13.0	No
            iPhone 8 Plus	2017-09-22	5.5	3GB	iOS 11.0	No
            iPhone X	2017-11-03	5.8	3GB	iOS 11.1	Yes
            iPhone XS	2018-09-21	5.8	4GB	iOS 12.0	Yes
            iPhone XS Max	2018-09-21	6.5	4GB	iOS 12.0	Yes
            iPhone XR	2016-09-25	4.7	4GB	iOS 13.0	No
            
        #row 삭제(원본 변형 안함)
        iphone_df.drop('iPhone XR',axis='index',inplace=False)
            
            >>
            출시일	디스플레이	메모리	출시 버전	Face ID
            iPhone 7	2016-09-16	4.7	2GB	iOS 10.0	No
            iPhone 7 Plus	2016-09-16	5.5	3GB	iOS 10.0	No
            iPhone 8	2016-09-25	4.7	4GB	iOS 13.0	No
            iPhone 8 Plus	2017-09-22	5.5	3GB	iOS 11.0	No
            iPhone X	2017-11-03	5.8	3GB	iOS 11.1	Yes
            iPhone XS	2018-09-21	5.8	4GB	iOS 12.0	Yes
            iPhone XS Max	2018-09-21	6.5	4GB	iOS 12.0	Yes
            
        iphone_df
            
            >>
            출시일	디스플레이	메모리	출시 버전	Face ID
            iPhone 7	2016-09-16	4.7	2GB	iOS 10.0	No
            iPhone 7 Plus	2016-09-16	5.5	3GB	iOS 10.0	No
            iPhone 8	2016-09-25	4.7	4GB	iOS 13.0	No
            iPhone 8 Plus	2017-09-22	5.5	3GB	iOS 11.0	No
            iPhone X	2017-11-03	5.8	3GB	iOS 11.1	Yes
            iPhone XS	2018-09-21	5.8	4GB	iOS 12.0	Yes
            iPhone XS Max	2018-09-21	6.5	4GB	iOS 12.0	Yes
            iPhone XR	2016-09-25	4.7	4GB	iOS 13.0	No
            
    index/column 설정하기
        
        liverpool_df=pd.read_csv('./data/liverpool.csv',index_col=0)
        liverpool_df
        
            >>
            position	born	number	nationality
            Roberto Firmino	FW	1991	no. 9	Brazil
            Sadio Mane	FW	1992	no. 10	Senegal
            Mohamed Salah	FW	1992	no. 11	Egypt
            Joe Gomez	DF	1997	no. 12	England
            Alisson Becker	GK	1992	no. 13	Brazil
            
        liverpool_df.rename(columns={'position':'Position'})
        
            >>
            Position	born	number	nationality
            Roberto Firmino	FW	1991	no. 9	Brazil
            Sadio Mane	FW	1992	no. 10	Senegal
            Mohamed Salah	FW	1992	no. 11	Egypt
            Joe Gomez	DF	1997	no. 12	England
            Alisson Becker	GK	1992	no. 13	Brazil
            
        liverpool_df
        
            >>
            position	born	number	nationality
            Roberto Firmino	FW	1991	no. 9	Brazil
            Sadio Mane	FW	1992	no. 10	Senegal
            Mohamed Salah	FW	1992	no. 11	Egypt
            Joe Gomez	DF	1997	no. 12	England
            Alisson Becker	GK	1992	no. 13	Brazil
            
        #사전형태로 컬럼이름 변경 가능
        liverpool_df.rename(columns={'position':'Position','born':'Born'},inplace=True)
        liverpool_df
        
            >>
            Position	Born	number	nationality
            Roberto Firmino	FW	1991	no. 9	Brazil
            Sadio Mane	FW	1992	no. 10	Senegal
            Mohamed Salah	FW	1992	no. 11	Egypt
            Joe Gomez	DF	1997	no. 12	England
            Alisson Becker	GK	1992	no. 13	Brazil
        
        #index 이름 변경 및 설정 가능
        liverpool_df.index.name='Player Name'
        liverpool_df
        
            >>
            Position	Born	number	nationality
            Player Name				
            Roberto Firmino	FW	1991	no. 9	Brazil
            Sadio Mane	FW	1992	no. 10	Senegal
            Mohamed Salah	FW	1992	no. 11	Egypt
            Joe Gomez	DF	1997	no. 12	England
            Alisson Becker	GK	1992	no. 13	Brazil
        
        #다른 column으로 index 설정가능 그러나 기존 index는 덮어써짐
        liverpool_df.set_index('number')
        
            >>
            Position	Born	nationality
            number			
            no. 9	FW	1991	Brazil
            no. 10	FW	1992	Senegal
            no. 11	FW	1992	Egypt
            no. 12	DF	1997	England
            no. 13	GK	1992	Brazil
            
        liverpool_df.index
        
            >>
            Index(['Roberto Firmino', 'Sadio Mane', 'Mohamed Salah', 'Joe Gomez',
                   'Alisson Becker'],
                  dtype='object', name='Player Name')
        
        #따라서 기존 인덱스를 따로 column을 생성해서 설정해줘야함
        liverpool_df['Player Name']=liverpool_df.index
        liverpool_df
        
            >>
            Position	Born	number	nationality	Player Name
            Player Name					
            Roberto Firmino	FW	1991	no. 9	Brazil	Roberto Firmino
            Sadio Mane	FW	1992	no. 10	Senegal	Sadio Mane
            Mohamed Salah	FW	1992	no. 11	Egypt	Mohamed Salah
            Joe Gomez	DF	1997	no. 12	England	Joe Gomez
            Alisson Becker	GK	1992	no. 13	Brazil	Alisson Becker
            number
        
        #number column으로 index 변경
        liverpool_df.set_index('number')
        
            >>
            Position	Born	nationality	Player Name
            number				
            no. 9	FW	1991	Brazil	Roberto Firmino
            no. 10	FW	1992	Senegal	Sadio Mane
            no. 11	FW	1992	Egypt	Mohamed Salah
            no. 12	DF	1997	England	Joe Gomez
            no. 13	GK	1992	Brazil	Alisson Becker
            
            
    큰 데이터 다루기
        
        laptops_df=pd.read_csv('./data/laptops.csv')
        
        #위에서 3개 데이터만 출력
        laptops_df.head(3)

            >>
            brand	model	ram	hd_type	hd_size	screen_size	price	processor_brand	processor_model	clock_speed	graphic_card_brand	graphic_card_size	os	weight	comments
            0	Dell	Inspiron 15-3567	4	hdd	1024	15.6	40000	intel	i5	2.5	intel	NaN	linux	2.50	NaN
            1	Apple	MacBook Air	8	ssd	128	13.3	55499	intel	i5	1.8	intel	2.0	mac	1.35	NaN
            2	Apple	MacBook Air	8	ssd	256	13.3	71500	intel	i5	1.8	intel	2.0	mac	1.35	NaN
        
        #끝에서 3개 데이터만 출력
        laptops_df.tail(5)

            >>
            brand	model	ram	hd_type	hd_size	screen_size	price	processor_brand	processor_model	clock_speed	graphic_card_brand	graphic_card_size	os	weight	comments
            162	Asus	A555LF	8	hdd	1024	15.6	39961	intel	i3 4th gen	1.7	nvidia	2.0	windows	2.3	NaN
            163	Asus	X555LA-XX172D	4	hdd	500	15.6	28489	intel	i3 4th gen	1.9	intel	NaN	linux	2.3	NaN
            164	Asus	X554LD	2	hdd	500	15.6	29199	intel	i3 4th gen	1.9	intel	1.0	linux	2.3	NaN
            165	Asus	X550LAV-XX771D	2	hdd	500	15.6	29990	intel	i3 4th gen	1.7	intel	NaN	linux	2.5	NaN
            166	Asus	X540LA-XX538T	4	hdd	1024	15.6	30899	intel	i3 5th gen	2.0	intel	NaN	windows	2.3	NaN
        
        #대략적인 크기 출력
        laptops_df.shape

            >>
            (167, 15)

        #컬럼 이름 확인
        laptops_df.columns

            >>
            Index(['brand', 'model', 'ram', 'hd_type', 'hd_size', 'screen_size', 'price',
                   'processor_brand', 'processor_model', 'clock_speed',
                   'graphic_card_brand', 'graphic_card_size', 'os', 'weight', 'comments'],
                  dtype='object')
        
        #컬럼의 기본적인 특징 출력
        laptops_df.info()

            >>
            <class 'pandas.core.frame.DataFrame'>
            RangeIndex: 167 entries, 0 to 166
            Data columns (total 15 columns):
             #   Column              Non-Null Count  Dtype  
            ---  ------              --------------  -----  
             0   brand               167 non-null    object 
             1   model               167 non-null    object 
             2   ram                 167 non-null    int64  
             3   hd_type             167 non-null    object 
             4   hd_size             167 non-null    int64  
             5   screen_size         167 non-null    float64
             6   price               167 non-null    int64  
             7   processor_brand     167 non-null    object 
             8   processor_model     167 non-null    object 
             9   clock_speed         166 non-null    float64
             10  graphic_card_brand  163 non-null    object 
             11  graphic_card_size   81 non-null     float64
             12  os                  167 non-null    object 
             13  weight              160 non-null    float64
             14  comments            55 non-null     object 
            dtypes: float64(4), int64(3), object(8)
            memory usage: 19.7+ KB
        
        #데이터들의 특징 출력
        laptops_df.describe()

            >>
            ram	hd_size	screen_size	price	clock_speed	graphic_card_size	weight
            count	167.000000	167.00000	167.000000	167.000000	166.000000	81.000000	160.000000
            mean	6.898204	768.91018	14.775210	64132.898204	2.321084	52.160494	2.250813
            std	3.787479	392.99080	1.376526	42797.674010	0.554187	444.134142	0.648446
            min	2.000000	32.00000	10.100000	13872.000000	1.100000	1.000000	0.780000
            25%	4.000000	500.00000	14.000000	35457.500000	1.900000	2.000000	1.900000
            50%	8.000000	1024.00000	15.600000	47990.000000	2.300000	2.000000	2.200000
            75%	8.000000	1024.00000	15.600000	77494.500000	2.600000	4.000000	2.600000
            max	16.000000	2048.00000	17.600000	226000.000000	3.800000	4000.000000	4.200000
        
        #가격 기준으로 정렬
        laptops_df.sort_values(by='price')

            >>
            brand	model	ram	hd_type	hd_size	screen_size	price	processor_brand	processor_model	clock_speed	graphic_card_brand	graphic_card_size	os	weight	comments
            148	Acer	Aspire SW3-016	2	ssd	32	10.1	13872	intel	Atom Z8300	1.44	intel	NaN	windows	1.2	NaN
            83	Acer	A315-31CDC UN.GNTSI.001	2	ssd	500	15.6	17990	intel	Celeron	1.10	intel	NaN	windows	2.1	NaN
            108	Acer	Aspire ES-15 NX.GKYSI.010	4	hdd	500	15.6	17990	amd	A4-7210	1.80	amd	NaN	windows	2.4	NaN
            100	Acer	A315-31-P4CRUN.GNTSI.002	4	hdd	500	15.6	18990	intel	pentium	1.10	intel	NaN	windows	NaN	NaN
            73	Acer	Aspire ES1-523	4	hdd	1024	15.6	19465	amd	A4-7210	1.80	amd	NaN	linux	2.4	NaN
            ...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
            154	Microsoft	Surface Book CR9-00013	8	ssd	128	13.5	178799	intel	i5	1.80	intel	NaN	windows	1.5	NaN
            31	Acer	Predator 17	16	ssd	256	17.3	178912	intel	i7	2.60	nvidia	NaN	windows	4.2	Integrated Graphics
            96	Alienware	AW13R3-7000SLV-PUS	8	ssd	256	13.3	190256	intel	i7	3.00	nvidia	6.0	windows	2.6	13.3 inch FHD (1920 x 1080) IPS Anti-Glare 300...
            90	Alienware	15 Notebook	16	hdd	1024	15.6	199000	intel	i7	2.60	nvidia	8.0	windows	3.5	Maximum Display Resolution : 1920 x 1080 pixel
            5	Apple	MacBook Pro (TouchBar)	16	ssd	512	15.0	226000	intel	i7	2.70	intel	2.0	mac	2.5	NaN
            167 rows × 15 columns
        
        #역순으로 정렬
        laptops_df.sort_values(by='price',ascending=False)

            >>
            brand	model	ram	hd_type	hd_size	screen_size	price	processor_brand	processor_model	clock_speed	graphic_card_brand	graphic_card_size	os	weight	comments
            5	Apple	MacBook Pro (TouchBar)	16	ssd	512	15.0	226000	intel	i7	2.70	intel	2.0	mac	2.5	NaN
            90	Alienware	15 Notebook	16	hdd	1024	15.6	199000	intel	i7	2.60	nvidia	8.0	windows	3.5	Maximum Display Resolution : 1920 x 1080 pixel
            96	Alienware	AW13R3-7000SLV-PUS	8	ssd	256	13.3	190256	intel	i7	3.00	nvidia	6.0	windows	2.6	13.3 inch FHD (1920 x 1080) IPS Anti-Glare 300...
            31	Acer	Predator 17	16	ssd	256	17.3	178912	intel	i7	2.60	nvidia	NaN	windows	4.2	Integrated Graphics
            154	Microsoft	Surface Book CR9-00013	8	ssd	128	13.5	178799	intel	i5	1.80	intel	NaN	windows	1.5	NaN
            ...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
            73	Acer	Aspire ES1-523	4	hdd	1024	15.6	19465	amd	A4-7210	1.80	amd	NaN	linux	2.4	NaN
            100	Acer	A315-31-P4CRUN.GNTSI.002	4	hdd	500	15.6	18990	intel	pentium	1.10	intel	NaN	windows	NaN	NaN
            108	Acer	Aspire ES-15 NX.GKYSI.010	4	hdd	500	15.6	17990	amd	A4-7210	1.80	amd	NaN	windows	2.4	NaN
            83	Acer	A315-31CDC UN.GNTSI.001	2	ssd	500	15.6	17990	intel	Celeron	1.10	intel	NaN	windows	2.1	NaN
            148	Acer	Aspire SW3-016	2	ssd	32	10.1	13872	intel	Atom Z8300	1.44	intel	NaN	windows	1.2	NaN
            167 rows × 15 columns
        
        #정렬한 내용 원본 반영
        laptops_df.sort_values(by='price',ascending=False,inplace=True)
        
        
    큰 series 다루기
        
        laptops_df=pd.read_csv('./data/laptops.csv')
        laptops_df['brand']

            >>
            0       Dell
            1      Apple
            2      Apple
            3      Apple
            4      Apple
                   ...  
            162     Asus
            163     Asus
            164     Asus
            165     Asus
            166     Asus
            Name: brand, Length: 167, dtype: object
        
        #겹치지는거 없애고 중복없이 출력
        laptops_df['brand'].unique()

            >>
            array(['Dell', 'Apple', 'Acer', 'HP', 'Lenovo', 'Alienware', 'Microsoft',
                   'Asus'], dtype=object)
        
        #몇번 겹치는지
        laptops_df['brand'].value_counts()

            >>
            HP           55
            Acer         35
            Dell         31
            Lenovo       18
            Asus          9
            Apple         7
            Microsoft     6
            Alienware     6
            Name: brand, dtype: int64
        
        #대략적인 정보 출력
        laptops_df['brand'].describe()

            >>
            count     167
            unique      8
            top        HP
            freq       55
            Name: brand, dtype: object
            
        
***데이터 시각화***
    텍스트로만 표현하기에는 조금 제한적이어서 DataScience/Graph에
    예시들 적어놨음
    
    기본 그래프 종류
    
        line    df.plot(kind='line')
            선형 그래프
            
        bar    df.plot(kind='bar',stacked=True)
            막대형 그래프
                
        pie    df['KBS'].plot(kind='pie')
            원형 그래프
            
        histogram    df.plot(kind='hist',y='Height',bins=20)
            마크버전 정규분포
        
        box_plot    df.plot(kind='box',y='Height')
            box형태로 25%마다 어딘지 표시+이상한 값 제거
            
        scatter    df.plot(kind='scatter',x='math',y='writing')
            점으로 data표현
            
        kde_plot    sns.kdeplot(body_df['Height'],bw=0.01)
            비연속적인 그래프를 부드러운 곡선으로 연속적이게
            
        distribution_plot    sns.distplot(body_df['Height'],bins=15)
            정규분포+막대그래프
            
        vilolin_plot    sns.violinplot(x=body_df['Height'])
            바이올린처럼 생긴 box_plot 시각적으로 이쁨
            
        등고선    sns.kdeplot(body_df['Height'],body_df['Weight'])
            등고선처럼 생긴 형태 같은 지점에 너무 많은 데이터가 몰려있을 때 용이함
            이런 경우 데이터 포인터가 서로 중복된다고 표현하고
            이러한 그래프를 입체적이라고 표현한다.
            
        앤스컴 콰르텟..?    sns.lmplot(data=body_df,y='Weight',x='Height')
            scatter에 대표하는 선하나
            
        catplot    sns.catplot(data=laptop_df,x='os',y='price',kind='box')
            색상(hue)과 행(row) 등을 동시에 사용하여 3 개 이상의 카테고리를 표현        
    
    그래프+
    
        stripplot    sns.stripplot(data=titanic, x="Survived", y="Age")
            sns.catplot(data=laptop_df,x='os',y='price',kind='strip',hue='processor_brand')
            데이터 포인터가 서로 중복되있을 때 산점도으로 보여줌
            
        swarmplot    sns.catplot(data=laptop_df,x='os',y='price',kind='swarm',hue='processor_brand')
            데이터 포인터가 서로 중복되있을 때 산점도으로 보여줌
            
        heatmap    sns.heatmap(df.corr())
            색을 통해서 얼마나 관련있는지를 표현
        
        jointplot    sns.jointplot(data=basic_info,x='Height',y='Weight')
            scatter+bar
            
        pairplot    sns.pairplot(tips)
            각각 쌍의 그래프를 보여줌
            
        rugplot    잘모름 추가바람
    
    PDF(Probability Density Function)
        확률 밀도 함수
        확률 밀도 함수는 데이터셋의 분포를 나타낸다.
        특정 구간의 확률은 그래프 아래 그 구간의 면적과 동일하다.
        그래프 아래의 모든 면적을 더하면 1이 된다.
        
    KDE(Kernel Density Estimation)
        실제 세계에서 모을 수 있는 데이터는 연속적이지 않기때문에
        부드로운 곡선이 아니라 직선이 나올 수 밖에 없다.
        KDE는 실제 분포랑 비슷하게 부드러운 곡선이 나오게 만들어줌
        
    상관계수
        어떤 두 값이 비례혹은 반비례관계가 있는지 확인하고 싶다면
        두 값 사이의 상관계수를 확인해 보면 된다.
            df.corr()
    
    EDA(Exploratory Data Analysis
        탐색적 데이터 분석
        데이터셋을 다양한 관점에서 살펴보고 탐색하면서 인사이트를 찾는 것
        
    클러스터 분석(Cluster Analysis)
        비슷한 성향끼리 그룹화해서 분석 혹은 그룹화하는 것
    
    새로운 인사이트 발견하기
        비슷해 보이거나 서로 관련있는 것들을 그룹지어서 결과를 내보면
        다양한 통찰을 얻을 수 있음
        
            df.sum(axis='columns')
            df[df['Genre'].str.contains('Blues')]
            df['Genre'].str.startswith('Blues')
            address=df['소재지도로명주소'].str.split(pat='-',n=1,expand=True)
            df['brand'].map(brand_nation)    #brand_nation=>dict

    groupby
        그룹지어서 분석할 때 사용함
        
            nation_groups=df.groupby('brand_nation')
            type(nation_groups)
            
                >>pandas.core.groupby.generic.DataFrameGroupBy
                
            nation_groups.count()
            nation_groups.max()
            nation_groups.mean()
            nation_groups.first()
            nation_groups.last()
            nation_groups.plot(kind='box',y='price')
            nation_groups.plot(kind='hist',y='price')
            
        평균함수(mean())이용해서 비율구하기
            df.loc[df['gender']=='M','gender']=0
            df.loc[df['gender']=='F','gender']=1

            groups=df.groupby('occupation')
            groups.mean()['gender'].sort_values(ascending=False)
            
        merge(합치기)
            관계있는 두 DataFrame을 합침
            
                pd.merge(price_df,quantity_df,on='Product',how='inner')
                #how 생략하면 기본으로 'inner'가 들어가고
                #left,right,outer등이 있음
                
                
***데이터 퀄리티 높이기***
    좋은 데이터의 기준&데이터 클리닝
        완결성
            데이터는 필수항목 + 선택항목으로 이뤄져있음
            필수 항목은 비어있으면 분석할 수 없기 때문에
            비어있는 값(결측값)의 여부를 확인해야 한다.
            pandas에선 NaN(Not a Number)로 표현함
            
            없는게 가장 좋고, 왜 생기는지 원인을 파악해야됨
            
                df.isnull().sum()    #비어있는 데이터 확인
                df.dropna(inplace=True)    #비어있는 데이터가 있다면 해당 row 삭제
                df.dropna(axis='columns')    #비어있는 데이터가 있다면 해당 column 삭제
                df.fillna(0)    #비어있는 값 0으로 채움
                df.fillna(df.mean(),inplace=True)
                df.fillna(df.median(),inplace=True)
            
        유일성
            동일한 데이터가 불필요하게 중복되어 있으면 안됨
                
                df.index
                df.index.value_counts()
                df.drop_duplicates(inplace=True)    #중복된 두 로우 중 하나 삭제
                df=df.T.drop_duplicates().T    #.T는 transpose의 약자로 col,row 뒤집기
            
        통일성
            데이터가 동일한 단위로 되어있어야함
            
        정확성
            데이터가 정확해야함
            다른 데이터와 너무 동떨어진 데이터를 이상점(outlier)라고함
            너무 비이상적인 데이터라면 제거해야함
            
            이상점을 판단하는 기준
                절대적인 기준은 없음
            
                IQR(Interquartile Range)
                    box_plot에서 25%(Q1)지점과 75%(Q3)지점 사이에 거리
                    
                Q1 지점과 Q3 지점에서 1.5 IQR을 넘어가는 데이터를
                pandas에서는 이상점이라고 봄
        
            이상점 대처
                잘못된 데이터면 고치거나 제거
                올바른 데이턴데 그래도 쓸모없으면 지우고
                필요한 데이터면 사용 이건 분석하는 사람이 판단
            
                    df.plot(kind='box',y='abv')
                    df['abv'].describe()
                    q1=df['abv'].quantile(0.25)    #q1에 해당하는 값
                    #quantile 분위수
                    #확률 분포를 동등한 확률 구간으로 나누는 구분 눈금들
                    q3=df['abv'].quantile(0.75)
                    iqr=q3-q1
                    condition=(df['abv']<q1-1.5*iqr)|(df['abv']>q3+1.5*iqr)
                    df.loc[2250,'abv']=0.055
                    df[condition].index
                    df.drop(df[condition].index,inplace=True)
                    df.plot(kind='box',y='abv') 
            
            관계적 이상점(Relational Outlier)
                두 변수의 관계를 고려했을 때 이상한 데이터
                    
                    df.plot(kind='scatter',x='reading score',y='writing score')
                    df.corr()
                    df[df['writing score']>100]
                    df.drop(51,inplace=True)
                    df.plot(kind='scatter',x='reading score',y='writing score')
                    df.corr()
                    condition=(df['writing score']>90)&(df['reading score']<40)
                    df[condition]
                    df.drop(373,inplace=True)
                    df.plot(kind='scatter',x='reading score',y='writing score')
                    df.corr()
                    
***tip***
    자주 발생하는 오류
        'Series' objects are mutable, thus they cannot be hashed
        ->인덱싱 할 때 Dataframe에 .loc 붙였는지 확인

    대각선 대칭되게 만들기(column이랑 row랑 바꾸기)
        대각행렬을 만들면 됨
        DataFrame에 .T붙이면 됨
        pd.DataFrame([day,samsong_series,hyundee_series],index=['day', 'samsong', 'hyundee']).T
        pd.DataFrame([day,samsong_series,hyundee_series],index=['day', 'samsong', 'hyundee']).transpose()
        
    컬럼명 출력하는데 ... 대신 전부 출력하고 싶다면
        print(df.columns.values)
        
        Notebook에선
        df.columns.values
        
    데이터 타입오류
        DataFrame을 처음에 생성할 때 설정할 수 있음
            
            museum = pd.read_csv("data/museum_3.csv", dtype={'지역번호': str})
            
    이게되네..
        df.drop() 할 때 
        
            df.drop(df[df['budget']>q3+5*iqr].index,inplace=True)
        
        이런 식으로 인덱스의 리스트뿐만 아니라
        .index로 나온 값도 사용할 수 있음
        